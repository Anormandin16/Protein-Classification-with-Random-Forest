{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv(\"C:/Users/Anorm/Downloads/train_X.csv\", index_col=0)\n",
    "train_y = pd.read_csv(\"C:/Users/Anorm/Downloads/train_y (1).csv\")\n",
    "test_X = pd.read_csv(\"C:/Users/Anorm/Downloads/test_X.csv\")\n",
    "ms_whim = pd.read_csv(\"C:/Users/Anorm/Downloads/MS-WHIM.csv\")\n",
    "dpps = pd.read_csv(\"C:/Users/Anorm/Downloads/DPPS.csv\")\n",
    "phys = pd.read_csv(\"C:/Users/Anorm/Downloads/Physical.csv\")\n",
    "st_scale = pd.read_csv(\"C:/Users/Anorm/Downloads/ST-scale.csv\")\n",
    "t_scale = pd.read_csv(\"C:/Users/Anorm/Downloads/T-scale.csv\")\n",
    "vhse_scale = pd.read_csv(\"C:/Users/Anorm/Downloads/VHSE-scale.csv\")\n",
    "z_scale = pd.read_csv(\"C:/Users/Anorm/Downloads/Z-scale.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31029, 2) (31029,) (20686, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_X.iloc[:,0]\n",
    "y = train_y.iloc[:, 1]\n",
    "X_test = test_X.drop(test_X.columns[0], axis=1)\n",
    "print(train_X.shape,y.shape,X_test.shape)\n",
    "test_Xs = test_X.drop(test_X.columns[1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aa_encoder():\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    aa_encoder = OneHotEncoder(sparse_output=False)\n",
    "    aa_encoder.fit(np.array(list(amino_acids)).reshape(-1, 1))\n",
    "    return aa_encoder\n",
    "\n",
    "aa_encoder = create_aa_encoder()\n",
    "\n",
    "def encode_sequence(sequence, max_length=None):\n",
    "    sequence = sequence[:max_length] if max_length else sequence\n",
    "    encoded = aa_encoder.transform(np.array(list(sequence)).reshape(-1, 1))\n",
    "    return encoded.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 237\n",
      "Shape of X_train_encoded: (31029, 4740)\n"
     ]
    }
   ],
   "source": [
    "# Determine the maximum sequence length in X_train\n",
    "max_length = X_train.str.len().max()\n",
    "\n",
    "print(f\"Maximum sequence length: {max_length}\")\n",
    "\n",
    "# Encode all sequences\n",
    "X_train_encoded = np.array([encode_sequence(seq, max_length) for seq in X_train])\n",
    "\n",
    "print(\"Shape of X_train_encoded:\", X_train_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test_combined: (20686, 4740)\n"
     ]
    }
   ],
   "source": [
    "# Encode test sequences\n",
    "X_test_encoded = np.array([encode_sequence(seq, max_length) for seq in test_Xs['ConstructedAASeq_cln']])\n",
    "\n",
    "print(\"Shape of X_test_combined:\", X_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding trained with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87      3777\n",
      "           1       0.77      0.89      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.86      0.85      6206\n",
      "weighted avg       0.86      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = rf_classifier.predict(X_test_encoded)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "results = pd.DataFrame({\n",
    "    'Id': test_X['Id'],\n",
    "    'Brightness': test_predictions\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding trained with Logistic performed better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Logistic Regression model...\n",
      "Validation Accuracy: 0.8919\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      3777\n",
      "           1       0.84      0.89      0.87      2429\n",
      "\n",
      "    accuracy                           0.89      6206\n",
      "   macro avg       0.88      0.89      0.89      6206\n",
      "weighted avg       0.89      0.89      0.89      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_encoded, y, test_size=0.2, random_state=42)\n",
    "# Train the Logistic Regression model\n",
    "print(\"Training the Logistic Regression model...\")\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = log_reg.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = log_reg.predict(X_test_encoded)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "results = pd.DataFrame({\n",
    "    'Id': test_X['Id'],\n",
    "    'Brightness': test_predictions\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then began trying to use the different descriptor features to encode. So below is every descriptor feature tried one at a time and trained using Random Forest. They all performed pretty similarly as far as accuracy and F1 score are concerned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_descriptor_df(df):\n",
    "    df = df.iloc[2:].reset_index(drop=True)\n",
    "    df.set_index(df.columns[1], inplace=True)\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(z_scale)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [02:04<00:00, 249.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [01:29<00:00, 231.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8493393490170802\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.85      6206\n",
      "weighted avg       0.86      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on test data...\n",
      "Predictions saved to 'predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "print(\"Making predictions on test data...\")\n",
    "test_predictions = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Append predictions to X_test\n",
    "X_test['Brightness'] = test_predictions\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "results = pd.DataFrame({\n",
    "    'Id': X_test['Id'],\n",
    "    'Brightness': X_test['Brightness']\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(ms_whim)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [03:04<00:00, 168.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [02:00<00:00, 172.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8470834676119884\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.85      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(dpps)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [04:37<00:00, 111.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [02:35<00:00, 133.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8464389300676765\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.85      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(phys)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [02:59<00:00, 172.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [01:59<00:00, 173.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8477280051563003\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.86      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(st_scale)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [03:51<00:00, 133.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [02:30<00:00, 137.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8445053174347406\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.81      2429\n",
      "\n",
      "    accuracy                           0.84      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.85      0.84      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(t_scale)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [03:19<00:00, 155.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [03:08<00:00, 109.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8466000644537545\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.85      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(vhse_scale)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [03:38<00:00, 142.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [02:26<00:00, 140.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8486948114727683\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.86      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used logistic to train this feature which like one hot encoding performed better than Random Forest. This final one performed best in the Kaggle getting a score of .87625. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Logistic Regression model...\n",
      "Validation Accuracy: 0.8930\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      3777\n",
      "           1       0.86      0.87      0.86      2429\n",
      "\n",
      "    accuracy                           0.89      6206\n",
      "   macro avg       0.89      0.89      0.89      6206\n",
      "weighted avg       0.89      0.89      0.89      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "# Train the Logistic Regression model\n",
    "print(\"Training the Logistic Regression model...\")\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = log_reg.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "results = pd.DataFrame({\n",
    "    'Id': test_X['Id'],\n",
    "    'Brightness': test_predictions\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
