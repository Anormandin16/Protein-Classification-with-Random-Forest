{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv(\"C:/Users/Anorm/Downloads/train_X.csv\", index_col=0)\n",
    "train_y = pd.read_csv(\"C:/Users/Anorm/Downloads/train_y (1).csv\")\n",
    "test_X = pd.read_csv(\"C:/Users/Anorm/Downloads/test_X.csv\")\n",
    "ms_whim = pd.read_csv(\"C:/Users/Anorm/Downloads/MS-WHIM.csv\")\n",
    "dpps = pd.read_csv(\"C:/Users/Anorm/Downloads/DPPS.csv\")\n",
    "phys = pd.read_csv(\"C:/Users/Anorm/Downloads/Physical.csv\")\n",
    "st_scale = pd.read_csv(\"C:/Users/Anorm/Downloads/ST-scale.csv\")\n",
    "t_scale = pd.read_csv(\"C:/Users/Anorm/Downloads/T-scale.csv\")\n",
    "vhse_scale = pd.read_csv(\"C:/Users/Anorm/Downloads/VHSE-scale.csv\")\n",
    "z_scale = pd.read_csv(\"C:/Users/Anorm/Downloads/Z-scale.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31029, 2) (31029,) (20686, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_X.iloc[:,0]\n",
    "y = train_y.iloc[:, 1]\n",
    "X_test = test_X.drop(test_X.columns[0], axis=1)\n",
    "print(train_X.shape,y.shape,X_test.shape)\n",
    "test_Xs = test_X.drop(test_X.columns[1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aa_encoder():\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    aa_encoder = OneHotEncoder(sparse_output=False)\n",
    "    aa_encoder.fit(np.array(list(amino_acids)).reshape(-1, 1))\n",
    "    return aa_encoder\n",
    "\n",
    "aa_encoder = create_aa_encoder()\n",
    "\n",
    "def encode_sequence(sequence, max_length=None):\n",
    "    sequence = sequence[:max_length] if max_length else sequence\n",
    "    encoded = aa_encoder.transform(np.array(list(sequence)).reshape(-1, 1))\n",
    "    return encoded.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 237\n",
      "Shape of X_train_encoded: (31029, 4740)\n"
     ]
    }
   ],
   "source": [
    "# Determine the maximum sequence length in X_train\n",
    "max_length = X_train.str.len().max()\n",
    "\n",
    "print(f\"Maximum sequence length: {max_length}\")\n",
    "\n",
    "# Encode all sequences\n",
    "X_train_encoded = np.array([encode_sequence(seq, max_length) for seq in X_train])\n",
    "\n",
    "print(\"Shape of X_train_encoded:\", X_train_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test_combined: (20686, 4740)\n"
     ]
    }
   ],
   "source": [
    "# Encode test sequences\n",
    "X_test_encoded = np.array([encode_sequence(seq, max_length) for seq in test_Xs['ConstructedAASeq_cln']])\n",
    "\n",
    "print(\"Shape of X_test_combined:\", X_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m rf_classifier \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mrf_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Make predictions on the validation set\u001b[39;00m\n\u001b[0;32m      9\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m rf_classifier\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[1;32mc:\\Users\\Anorm\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anorm\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:363\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[1;32mc:\\Users\\Anorm\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Anorm\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Anorm\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anorm\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = rf_classifier.predict(X_test_encoded)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "results = pd.DataFrame({\n",
    "    'Id': test_X['Id'],\n",
    "    'Brightness': test_predictions\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {'solver': ['liblinear'], 'penalty': ['l1'], 'C': [.001,0.01,0.1,1,10,100],'max_iter':[100,500,1000,10000]}\n",
    "\n",
    "\n",
    "L1_Logistic = LogisticRegression()\n",
    "\n",
    "grid_search_l1= GridSearchCV(L1_Logistic, param_grid, cv=5,scoring='f1_macro')\n",
    "grid_search_l1.fit(X_train_encoded, y)\n",
    "\n",
    "\n",
    "print('Best Optimal hyperparameter combination:', grid_search_l1.best_params_, 'F1 score:', round(grid_search_l1.best_score_, 4))\n",
    "best_l1_model = grid_search_l1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Logistic Regression model...\n",
      "Validation Accuracy: 0.8919\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      3777\n",
      "           1       0.84      0.89      0.87      2429\n",
      "\n",
      "    accuracy                           0.89      6206\n",
      "   macro avg       0.88      0.89      0.89      6206\n",
      "weighted avg       0.89      0.89      0.89      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_encoded, y, test_size=0.2, random_state=42)\n",
    "# Train the Logistic Regression model\n",
    "print(\"Training the Logistic Regression model...\")\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = log_reg.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = log_reg.predict(X_test_encoded)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "results = pd.DataFrame({\n",
    "    'Id': test_X['Id'],\n",
    "    'Brightness': test_predictions\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_descriptor_df(df):\n",
    "    df = df.iloc[2:].reset_index(drop=True)\n",
    "    df.set_index(df.columns[1], inplace=True)\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(z_scale)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [02:04<00:00, 249.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [01:29<00:00, 231.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8493393490170802\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.85      6206\n",
      "weighted avg       0.86      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on test data...\n",
      "Predictions saved to 'predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "print(\"Making predictions on test data...\")\n",
    "test_predictions = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Append predictions to X_test\n",
    "X_test['Brightness'] = test_predictions\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "results = pd.DataFrame({\n",
    "    'Id': X_test['Id'],\n",
    "    'Brightness': X_test['Brightness']\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DPPS good-08\n",
    "#MS-Whim good-98\n",
    "#Physical -2018\n",
    "#St-scale -2009 - competent\n",
    "#T-scale -2007 - ok\n",
    "#VHSe -2005 -ok\n",
    "#Z-scale -1987\n",
    "\n",
    "\n",
    "\n",
    "#Combine strongest descriptors in each set and use those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(ms_whim)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [03:04<00:00, 168.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [02:00<00:00, 172.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8470834676119884\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.85      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(dpps)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [04:37<00:00, 111.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [02:35<00:00, 133.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8464389300676765\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.85      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(phys)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [02:59<00:00, 172.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [01:59<00:00, 173.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8477280051563003\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.86      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(st_scale)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [03:51<00:00, 133.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [02:30<00:00, 137.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8445053174347406\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.81      2429\n",
      "\n",
      "    accuracy                           0.84      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.85      0.84      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(t_scale)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [03:19<00:00, 155.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [03:08<00:00, 109.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8466000644537545\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.85      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = clean_descriptor_df(vhse_scale)\n",
    "\n",
    "def sequence_to_features(sequence, descriptor):\n",
    "    features = []\n",
    "    for aa in sequence:\n",
    "        if aa in descriptor.index:\n",
    "            features.extend(descriptor.loc[aa].values)\n",
    "        else:\n",
    "            features.extend([0] * len(descriptor.columns))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31029/31029 [03:38<00:00, 142.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training data\n",
    "print(\"Encoding training data...\")\n",
    "X_train_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(X_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20686/20686 [02:26<00:00, 140.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode test data\n",
    "print(\"Encoding test data...\")\n",
    "X_test_features = np.array([sequence_to_features(seq, descriptor) for seq in tqdm(test_Xs['ConstructedAASeq_cln'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_test_scaled = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Validation Accuracy: 0.8486948114727683\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3777\n",
      "           1       0.77      0.87      0.82      2429\n",
      "\n",
      "    accuracy                           0.85      6206\n",
      "   macro avg       0.84      0.85      0.84      6206\n",
      "weighted avg       0.86      0.85      0.85      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Logistic Regression model...\n",
      "Validation Accuracy: 0.8930\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      3777\n",
      "           1       0.86      0.87      0.86      2429\n",
      "\n",
      "    accuracy                           0.89      6206\n",
      "   macro avg       0.89      0.89      0.89      6206\n",
      "weighted avg       0.89      0.89      0.89      6206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train, y_val = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "# Train the Logistic Regression model\n",
    "print(\"Training the Logistic Regression model...\")\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = log_reg.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "results = pd.DataFrame({\n",
    "    'Id': test_X['Id'],\n",
    "    'Brightness': test_predictions\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
